import os
import json
import requests
import numpy as np
import tempfile
import time
import subprocess
from tqdm import tqdm
from multiprocessing import Pool, cpu_count

from spotify_app.services.apple_client import extract_features_from_audio


# ======================================================
# ì €ì¥ ê²½ë¡œ ì„¤ì •
# ======================================================
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
OUTPUT_DIR = os.path.abspath(os.path.join(BASE_DIR, "..", "data", "apple_db"))

os.makedirs(OUTPUT_DIR, exist_ok=True)

VECTORS_OUT = os.path.join(OUTPUT_DIR, "apple_vectors.npy")
META_OUT = os.path.join(OUTPUT_DIR, "apple_metadata.json")

SEARCH_URL = "https://itunes.apple.com/search"
LOOKUP_URL = "https://itunes.apple.com/lookup"

AUDIO_DIM = 37
LIMIT_PER_TERM = 200


# ======================================================
# ê²€ìƒ‰ term ëª©ë¡
# ======================================================
SEARCH_TERMS = []

# ì•ŒíŒŒë²³ ê²€ìƒ‰ ì¶”ê°€ (26ê°œ)
for ch in "abcdefghijklmnopqrstuvwxyz":
    SEARCH_TERMS.append(ch)

# 2â€“3ê¸€ì keyword ì¶”ê°€
COMMON = ["lo", "li", "he", "me", "sa", "ta"]
SEARCH_TERMS += COMMON

# ì¼ë°˜ ì˜ì–´ ë‹¨ì–´ ì¶”ê°€
BASIC = ["love", "you", "me", "night", "time", "life", "dream"]
SEARCH_TERMS += BASIC


# ======================================================
# ê¸°ë³¸ ìœ í‹¸ í•¨ìˆ˜
# ======================================================
def safe_json(r):
    try:
        return r.json()
    except:
        return None


def convert_to_wav(input_path, output_path):
    cmd = [
        "ffmpeg", "-y",
        "-loglevel", "quiet",
        "-i", input_path,
        "-ar", "22050",
        "-ac", "1",
        output_path
    ]

    subprocess.run(cmd, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)

    if os.path.exists(output_path) and os.path.getsize(output_path) > 0:
        return output_path
    return None

def search_task(args):
        term, country = args
        return search_track_ids(term, country)

# ======================================================
# 1) Search API
# ======================================================
def search_track_ids(term, country="US"):
    params = {
        "term": term,
        "media": "music",
        "entity": "song",
        "limit": LIMIT_PER_TERM,
        "country": country
    }

    for attempt in range(2):
        try:
            r = requests.get(SEARCH_URL, params=params, timeout=5)
            data = safe_json(r)
            if data:
                time.sleep(0.15)
                return [item.get("trackId") for item in data.get("results", []) if item.get("trackId")]
        except:
            pass

        time.sleep(0.15)

    print(f"[Search Error] term='{term}' ì‹¤íŒ¨")
    return []


# ======================================================
# 2) Lookup API
# ======================================================
def lookup_tracks_batch(track_ids):
    joined = ",".join(str(tid) for tid in track_ids)
    params = {"id": joined, "entity": "song"}

    for attempt in range(2):
        try:
            r = requests.get(LOOKUP_URL, params=params, timeout=5)
            data = safe_json(r)
            if data:
                return data.get("results", [])
        except:
            pass

        time.sleep(0.05)

    print("[Lookup Error] batch ì¡°íšŒ ì‹¤íŒ¨")
    return []


# ======================================================
# Metadata vector builder
# ======================================================
def explicit_to_numeric(value: str):
    mapping = {"notExplicit": 0, "cleaned": 1, "explicit": 2}
    return mapping.get(value, 0)


def build_metadata_vector(item):
    release_year = 0
    if item.get("releaseDate"):
        release_year = int(item["releaseDate"][:4])

    return [
        item.get("primaryGenreId", 0),
        item.get("trackTimeMillis", 0),
        explicit_to_numeric(item.get("trackExplicitness")),
        1, 1, 1,
        release_year
    ]


# ======================================================
# ğŸ”¥ ë³‘ë ¬ë¡œ ì‹¤í–‰ë˜ëŠ” ì‘ì—… í•¨ìˆ˜ (ê°€ì¥ ì¤‘ìš”)
# ======================================================
def process_track(item):
    """
    previewUrl ë‹¤ìš´ë¡œë“œ â†’ m4a â†’ wav ë³€í™˜ â†’ feature ì¶”ì¶œ
    ì‹¤íŒ¨ ì‹œ None ë°˜í™˜
    """
    preview = item["previewUrl"]
    track_id = item["trackId"]

    # 1) m4a ë‹¤ìš´ë¡œë“œ
    try:
        with tempfile.NamedTemporaryFile(delete=False, suffix=".m4a") as tmp:
            r = requests.get(preview, timeout=10)
            tmp.write(r.content)
            m4a_path = tmp.name
    except:
        return None

    # 2) m4a â†’ wav
    wav_path = m4a_path.replace(".m4a", ".wav")
    wav_path = convert_to_wav(m4a_path, wav_path)
    os.remove(m4a_path)

    if not wav_path:
        return None

    # 3) Feature extract
    try:
        audio_vec = extract_features_from_audio(wav_path)
    except:
        audio_vec = None

    os.remove(wav_path)

    if audio_vec is None or len(audio_vec) != AUDIO_DIM:
        return None

    # 4) metadata vector
    meta_vec = build_metadata_vector(item)
    final_vec = np.concatenate([audio_vec, np.array(meta_vec)])

    # ìµœì¢… ë°˜í™˜ ê°’
    return {
        "track_id": track_id,
        "title": item.get("trackName"),
        "artist": item.get("artistName"),
        "preview_url": preview,
        "genre_id": item.get("primaryGenreId"),
        "release_date": item.get("releaseDate"),
        "vector": final_vec.tolist()
    }


# ======================================================
# ë©”ì¸ ë¡œì§
# ======================================================
def build_apple_dataset():
    print("\nğŸµ Apple Music dataset ìˆ˜ì§‘ ì‹œì‘...")

    # ----------------------------------------------
    # 1) Search (ë³‘ë ¬ ì²˜ë¦¬)
    # ----------------------------------------------
    COUNTRIES = ["US", "JP", "KR"]

    # term-country ëª¨ë“  ì¡°í•© ìƒì„±
    tasks = []
    for term in SEARCH_TERMS:
        for country in COUNTRIES:
            tasks.append((term, country))

    print("\nğŸ” Parallel Searching terms...")

    all_ids = []
    with Pool(processes=max(cpu_count() // 2, 2)) as pool:
        results = list(tqdm(pool.imap(search_task, tasks), total=len(tasks)))

    for ids in results:
        all_ids.extend(ids)

    unique_ids = list(set(all_ids))
    print(f"\nğŸ” trackId í›„ë³´: {len(unique_ids)} ê°œ")

    # ----------------------------------------------
    # 2) Lookup
    # ----------------------------------------------
    metadata_full = []
    batch_size = 200

    print("\nğŸ“¡ Running Lookup batches...")

    for i in tqdm(range(0, len(unique_ids), batch_size)):
        batch = unique_ids[i:i + batch_size]
        results = lookup_tracks_batch(batch)

        for item in results:
            if item.get("previewUrl") and item.get("trackId"):
                metadata_full.append(item)

    print(f"\nğŸ§ previewUrl ì¡´ì¬í•˜ëŠ” ê³¡: {len(metadata_full)} ê°œ")

    # ----------------------------------------------
    # ğŸ”¥ 3) ë³‘ë ¬ Feature Extraction
    # ----------------------------------------------
    print("\nğŸ§ Extracting audio features (Parallel)...")

    num_workers = max(cpu_count() - 1, 2)
    print(f"ğŸ§µ ë³‘ë ¬ í”„ë¡œì„¸ìŠ¤: {num_workers} core(s)")

    final_vectors = []
    metadata_list = []

    with Pool(processes=num_workers) as pool:
        for result in tqdm(pool.imap(process_track, metadata_full), total=len(metadata_full)):
            if result:
                metadata_list.append({
                    "track_id": result["track_id"],
                    "title": result["title"],
                    "artist": result["artist"],
                    "preview_url": result["preview_url"],
                    "genre_id": result["genre_id"],
                    "release_date": result["release_date"]
                })
                final_vectors.append(result["vector"])

    # ----------------------------------------------
    # 4) Save
    # ----------------------------------------------
    np.save(VECTORS_OUT, np.array(final_vectors))

    with open(META_OUT, "w", encoding="utf-8") as f:
        json.dump(metadata_list, f, indent=2, ensure_ascii=False)

    print("\n=======================================")
    print("âœ… Apple DB ìƒì„± ì™„ë£Œ!")
    print(f"ğŸ“¦ ë²¡í„° ê°œìˆ˜: {len(final_vectors)} tracks")
    print(f"ğŸ“Œ ì €ì¥ ìœ„ì¹˜: {VECTORS_OUT}")
    print("=======================================")


# ======================================================
if __name__ == "__main__":
    build_apple_dataset()
